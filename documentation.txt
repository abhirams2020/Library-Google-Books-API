API

fetch(`https://openlibrary.org/search.json?q=${searchTerm}`)
.then(response => response.json())
.then(data => {
  displayResults(data.docs);
})
.catch(error => {
  console.error("Error fetching data:", error);
});

Fetches api data with given search term. Response.status is 200 if it exists. Else response can be 404/500.

Npm init in folder to start project and create package.json

Start and Kill http-server (localhost)

npm install -g http-server

http-server -p 8080

npx kill-port 8080

postgres queries were not working in script.js because not ended with ';'

hiding password using dotenv in nodejs. (imp)
https://northflank.com/guides/connecting-to-a-postgresql-database-using-node-js
PG_HOST=<postgres hostname>
PG_PORT=<postgres port>
PG_USER=<postgres database user>
PG_PASSWORD=<postgres database password>
PG_DATABASE=<postgres database name>

add pagination in postgres queries.
      const page = parseInt(req.query.page) || 1;   // Get the requested page, default to 1
      const itemsPerPage = parseInt(req.query.itemsPerPage) || 10; // Get items per page, default to 10

add search term in postgres queries
SELECT * FROM books WHERE title LIKE '%book%' - case sensitive
SELECT * FROM books WHERE title ILIKE '%book%' - case insensitive

migrating data from google books api to local db 
fetch data repeatedy using for loop and do insert into table values.
might require some wait time in loop to avoid ddos attack
need to check if title is not null and date is in valid format.

hit enter to search
  searchInput.addEventListener("keydown", (event) => {
    if (event.key === "Enter") {

Steps

1. Created basic webpage which fetches data from google books api and shows in page
2. Added pagination to make page loading faster. No need to get all results at once.
3. Implemented a view details button which shows popup modal with all details on click.
4. Need to transfer data from google books api to local postgres
5. Authentication of requests using API key.